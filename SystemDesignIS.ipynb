{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUpChvbyxyst"
      },
      "outputs": [],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import stanza\n",
        "\n",
        "stanza.download('en')  # run once\n",
        "nlp = stanza.Pipeline(\n",
        "    lang='en',\n",
        "    processors='tokenize,pos,lemma,depparse,ner,constituency,coref'\n",
        ")"
      ],
      "metadata": {
        "id": "SCgLlVl2x4XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnalyzerBase:\n",
        "    \"\"\"Base class for text analysis modules. Handles file loading and provides a template interface.\n",
        "\n",
        "    This class loads a dataset from either a .csv or .xlsx file into a pandas DataFrame.\n",
        "    Subclasses must implement the `run()` method to define specific analysis logic.\n",
        "\n",
        "    Attributes:\n",
        "        df (pd.DataFrame): The loaded DataFrame with missing values replaced by empty strings.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath):\n",
        "        \"\"\"Initializes the AnalyzerBase by loading a CSV or Excel file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the input file. Must be either a `.csv` or `.xlsx`.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the file format is not supported.\n",
        "        \"\"\"\n",
        "        if filepath.endswith(\".xlsx\"):\n",
        "            self.df = pd.read_excel(filepath)\n",
        "            print(self.df)\n",
        "        elif filepath.endswith(\".csv\"):\n",
        "            self.df = pd.read_csv(filepath)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format. Please provide a .csv or .xlsx file.\")\n",
        "\n",
        "        self.df.fillna('', inplace=True)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Abstract method to be implemented by all subclasses.\n",
        "\n",
        "        This method defines the core logic of the analysis task.\n",
        "\n",
        "        Raises:\n",
        "            NotImplementedError: Always, unless overridden in a child class.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "class EntailmentAnalyzer(AnalyzerBase):\n",
        "    \"\"\"Performs semantic entailment analysis between a sentence and its context.\n",
        "\n",
        "    This class uses a zero-shot classification model (BART large MNLI) to measure\n",
        "    how well the sentence is semantically entailed by the preceding and following story parts.\n",
        "\n",
        "    Attributes:\n",
        "        classifier: A HuggingFace pipeline for zero-shot classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath):\n",
        "        \"\"\"Initializes the entailment analyzer and loads the dataset and model.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the input CSV or XLSX file.\n",
        "        \"\"\"\n",
        "        super().__init__(filepath)\n",
        "        self.classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "    def get_entailment_score(self, context, hypothesis):\n",
        "        \"\"\"Calculates semantic entailment score between a hypothesis and a context.\n",
        "\n",
        "        Uses a zero-shot classification model to predict how well the hypothesis\n",
        "        (i.e., sentence) is entailed by the context (e.g., Pre_Story or Post_Story).\n",
        "\n",
        "        Args:\n",
        "            context (str): The context to test against (as the candidate label).\n",
        "            hypothesis (str): The sentence to evaluate (as the hypothesis).\n",
        "\n",
        "        Returns:\n",
        "            float: Entailment score between 0.0 and 1.0. Returns 0.0 for empty inputs.\n",
        "        \"\"\"\n",
        "        if not context.strip() or not hypothesis.strip():\n",
        "            return 0.0\n",
        "        result = self.classifier(hypothesis, candidate_labels=[context], hypothesis_template=\"This sentence is about {}.\")\n",
        "        return result['scores'][0]\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Runs the full entailment analysis on the loaded dataset.\n",
        "\n",
        "        For each row:\n",
        "        - Computes entailment score between 'Sentence' and 'Pre_Story' → `Pre_ent_score`\n",
        "        - Computes entailment score between 'Sentence' and 'Post_Story' → `Post_ent_score`\n",
        "\n",
        "        It also:\n",
        "        - Divides rows into bins: 'Bin 1' for the first 10, then each 10 rows → Bin 2, 3, ...\n",
        "        - Adds a row at the end of each bin showing the average entailment scores.\n",
        "        - Inserts an empty row between bins for readability.\n",
        "\n",
        "        Outputs:\n",
        "            CSV file: 'big_story_entailment.csv'\n",
        "        \"\"\"\n",
        "        tqdm.pandas()\n",
        "\n",
        "        # Compute entailment scores\n",
        "        self.df['Pre_ent_score'] = self.df.progress_apply(\n",
        "            lambda row: self.get_entailment_score(str(row['Sentence']), str(row['Pre_Story'])), axis=1)\n",
        "        self.df['Post_ent_score'] = self.df.progress_apply(\n",
        "            lambda row: self.get_entailment_score(str(row['Sentence']), str(row['Post_Story'])), axis=1)\n",
        "\n",
        "        # Assign Bin labels\n",
        "        bin_labels = []\n",
        "        for i in range(len(self.df)):\n",
        "            if i < 10:\n",
        "                bin_labels.append(\"Bin 1\")\n",
        "            else:\n",
        "                bin_num = ((i - 10) // 10) + 2\n",
        "                bin_labels.append(f\"Bin {bin_num}\")\n",
        "        self.df['Bin'] = bin_labels\n",
        "\n",
        "        # Insert empty rows and average rows between bins\n",
        "        final_rows = []\n",
        "        for bin_name, group in self.df.groupby('Bin'):\n",
        "            # Add the group's rows\n",
        "            for _, row in group.iterrows():\n",
        "                final_rows.append(row)\n",
        "\n",
        "            # Add average row\n",
        "            avg_row = pd.Series({\n",
        "                'Pre_ent_score': group['Pre_ent_score'].mean(),\n",
        "                'Post_ent_score': group['Post_ent_score'].mean(),\n",
        "                'Bin': bin_name,\n",
        "                'Sentence': '[Average]',  # optional marker\n",
        "            })\n",
        "            final_rows.append(avg_row)\n",
        "\n",
        "            # Add blank row\n",
        "            final_rows.append(pd.Series(dtype=object))\n",
        "\n",
        "        # Create final DataFrame\n",
        "        final_df = pd.DataFrame(final_rows)\n",
        "\n",
        "        # Save to CSV\n",
        "        final_df.to_csv('big_story_entailment.csv', index=False)\n",
        "        print(\"✅ Entailment scores saved to 'big_story_entailment.csv'\")\n",
        "\n",
        "\n",
        "class CoherenceAnalyzer(AnalyzerBase):\n",
        "    \"\"\"Performs coherence analysis by computing sentence similarity scores using a sentence transformer model.\n",
        "\n",
        "    This analyzer compares the central sentence against its surrounding context (Pre_Story and Post_Story)\n",
        "    using cosine similarity between sentence embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath):\n",
        "        \"\"\"Initializes the CoherenceAnalyzer with a transformer model and loads input data.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the input CSV or XLSX file.\n",
        "        \"\"\"\n",
        "        super().__init__(filepath)\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    def compute_similarity(self, base, other):\n",
        "        \"\"\"Computes cosine similarity between two text segments using sentence embeddings.\n",
        "\n",
        "        Args:\n",
        "            base (str): The base sentence to compare from.\n",
        "            other (str): The sentence to compare to.\n",
        "\n",
        "        Returns:\n",
        "            float: Cosine similarity score ranging between -1 and 1.\n",
        "        \"\"\"\n",
        "        embeddings = self.model.encode([base, other], convert_to_tensor=True)\n",
        "        return util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Executes the coherence analysis workflow.\n",
        "\n",
        "        For each row in the dataset:\n",
        "        - Computes similarity between 'Sentence' and 'Pre_Story' → `Pre_similarity`\n",
        "        - Computes similarity between 'Sentence' and 'Post_Story' → `Post_similarity`\n",
        "\n",
        "        Then:\n",
        "        - Assigns each row to a bin: 'Bin 1' contains first 10 rows, each subsequent bin contains 10 rows\n",
        "        - Computes and inserts an average row for each bin with mean similarity scores\n",
        "        - Inserts a blank row between bins for formatting\n",
        "\n",
        "        Output:\n",
        "            CSV file: 'big_story_coherence_scores.csv' with added similarity scores and bin averages\n",
        "        \"\"\"\n",
        "        tqdm.pandas()\n",
        "\n",
        "        # Calculate similarity scores\n",
        "        self.df['Pre_similarity'] = self.df.progress_apply(\n",
        "            lambda row: self.compute_similarity(str(row['Sentence']), str(row['Pre_Story'])), axis=1)\n",
        "        self.df['Post_similarity'] = self.df.progress_apply(\n",
        "            lambda row: self.compute_similarity(str(row['Sentence']), str(row['Post_Story'])), axis=1)\n",
        "\n",
        "        # Assign Bin labels\n",
        "        bin_labels = []\n",
        "        for i in range(len(self.df)):\n",
        "            if i < 10:\n",
        "                bin_labels.append(\"Bin 1\")\n",
        "            else:\n",
        "                bin_num = ((i - 10) // 10) + 2\n",
        "                bin_labels.append(f\"Bin {bin_num}\")\n",
        "        self.df['Bin'] = bin_labels\n",
        "\n",
        "        # Insert rows: original, per-bin average, and blank between bins\n",
        "        final_rows = []\n",
        "        for bin_name, group in self.df.groupby('Bin'):\n",
        "            for _, row in group.iterrows():\n",
        "                final_rows.append(row)\n",
        "\n",
        "            # Add average row for the bin\n",
        "            avg_row = pd.Series({\n",
        "                'Pre_similarity': group['Pre_similarity'].mean(),\n",
        "                'Post_similarity': group['Post_similarity'].mean(),\n",
        "                'Bin': bin_name,\n",
        "                'Sentence': '[Average]'  # optional label\n",
        "            })\n",
        "            final_rows.append(avg_row)\n",
        "\n",
        "            # Add empty row\n",
        "            final_rows.append(pd.Series(dtype=object))\n",
        "\n",
        "        # Create final DataFrame\n",
        "        final_df = pd.DataFrame(final_rows)\n",
        "\n",
        "        # Save to CSV\n",
        "        final_df.to_csv('big_story_coherence_scores.csv', index=False)\n",
        "        print(\"✅ Coherence scores saved to 'big_story_coherence_scores.csv'\")\n",
        "\n",
        "\n",
        "class AverageCoherenceAnalyzer(AnalyzerBase):\n",
        "    \"\"\"Analyzes sentence-level coherence across full story contexts.\n",
        "\n",
        "    Calculates the average semantic similarity between all consecutive sentence pairs\n",
        "    within a composite story: Pre_Story + Sentence + Post_Story.\n",
        "\n",
        "    Attributes:\n",
        "        model: A SentenceTransformer model used to compute sentence embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filepath):\n",
        "        \"\"\"Initializes the analyzer and loads the sentence transformer model.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the input CSV or XLSX file.\n",
        "        \"\"\"\n",
        "        super().__init__(filepath)\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    def compute_similarity(self, s1, s2):\n",
        "        \"\"\"Computes cosine similarity between two text segments.\n",
        "\n",
        "        Args:\n",
        "            s1 (str): The first sentence.\n",
        "            s2 (str): The second sentence.\n",
        "\n",
        "        Returns:\n",
        "            float: Cosine similarity between sentence embeddings.\n",
        "        \"\"\"\n",
        "        embeddings = self.model.encode([s1, s2], convert_to_tensor=True)\n",
        "        return util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "\n",
        "    def calculate_average_coherence(self, text):\n",
        "        \"\"\"Calculates the average coherence of a multi-sentence text.\n",
        "\n",
        "        Args:\n",
        "            text (str): A block of text formed by joining Pre_Story, Sentence, and Post_Story.\n",
        "\n",
        "        Returns:\n",
        "            float: The average similarity between all adjacent sentence pairs.\n",
        "        \"\"\"\n",
        "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
        "        if len(sentences) < 2:\n",
        "            return 0\n",
        "        scores = [self.compute_similarity(sentences[i], sentences[i+1])\n",
        "                  for i in range(len(sentences)-1)]\n",
        "        return sum(scores) / len(scores)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Executes the average coherence analysis for the full story segment.\n",
        "\n",
        "        Steps:\n",
        "        - Combines Pre_Story, Sentence, and Post_Story into a unified text block.\n",
        "        - Computes average coherence for each row.\n",
        "        - Organizes rows into bins:\n",
        "            - Bin 1 for the first 10 rows\n",
        "            - Bin 2, 3, ... for every subsequent group of 10 rows\n",
        "        - Appends an average row per bin with the mean 'Average_Coherence'\n",
        "        - Inserts an empty row after each bin for readability\n",
        "\n",
        "        Output:\n",
        "            CSV file: 'full_story_average_coherence_scores.csv'\n",
        "        \"\"\"\n",
        "        tqdm.pandas()\n",
        "\n",
        "        # Calculate average coherence\n",
        "        self.df['Average_Coherence'] = self.df.progress_apply(\n",
        "            lambda row: self.calculate_average_coherence(\n",
        "                str(row['Pre_Story']) + \" \" + str(row['Sentence']) + \" \" + str(row['Post_Story'])), axis=1)\n",
        "\n",
        "        # Assign Bin labels\n",
        "        bin_labels = []\n",
        "        for i in range(len(self.df)):\n",
        "            if i < 10:\n",
        "                bin_labels.append(\"Bin 1\")\n",
        "            else:\n",
        "                bin_num = ((i - 10) // 10) + 2\n",
        "                bin_labels.append(f\"Bin {bin_num}\")\n",
        "        self.df['Bin'] = bin_labels\n",
        "\n",
        "        # Insert original rows, per-bin average row, and empty line\n",
        "        final_rows = []\n",
        "        for bin_name, group in self.df.groupby('Bin'):\n",
        "            for _, row in group.iterrows():\n",
        "                final_rows.append(row)\n",
        "\n",
        "            # Add average row for this bin\n",
        "            avg_row = pd.Series({\n",
        "                'Average_Coherence': group['Average_Coherence'].mean(),\n",
        "                'Bin': bin_name,\n",
        "                'Sentence': '[Average]'\n",
        "            })\n",
        "            final_rows.append(avg_row)\n",
        "\n",
        "            # Add empty row\n",
        "            final_rows.append(pd.Series(dtype=object))\n",
        "\n",
        "        # Create final DataFrame\n",
        "        final_df = pd.DataFrame(final_rows)\n",
        "\n",
        "        # Save to CSV\n",
        "        final_df.to_csv('full_story_average_coherence_scores.csv', index=False)\n",
        "        print(\"✅ Average coherence scores saved to 'full_story_average_coherence_scores.csv'\")\n",
        "\n",
        "\n",
        "class CoreferenceAnalyzer(AnalyzerBase):\n",
        "    \"\"\"Analyzes coreference chains in a text to determine whether a target phrase is referenced\n",
        "    in the surrounding context (pre and post story).\n",
        "\n",
        "    Uses a coreference resolution NLP model (e.g., Stanza or AllenNLP) to track mentions of the\n",
        "    target phrase across the full story context.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath):\n",
        "        \"\"\"Initializes the coreference analyzer with a file and NLP model.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Path to the CSV or Excel file containing story data.\n",
        "        \"\"\"\n",
        "        super().__init__(filepath)\n",
        "        self.nlp = nlp\n",
        "\n",
        "    def get_region(self, offset, pre_length, main_start, main_length):\n",
        "        \"\"\"Determines whether a character offset falls in the pre, main, or post region.\n",
        "\n",
        "        Args:\n",
        "            offset (int): The character offset of a mention.\n",
        "            pre_length (int): Length of the pre-story text.\n",
        "            main_start (int): Starting character index of the main sentence.\n",
        "            main_length (int): Length of the main sentence.\n",
        "\n",
        "        Returns:\n",
        "            str: One of 'pre', 'main', or 'post'.\n",
        "        \"\"\"\n",
        "        if offset < pre_length:\n",
        "            return 'pre'\n",
        "        elif main_start <= offset < main_start + main_length:\n",
        "            return 'main'\n",
        "        else:\n",
        "            return 'post'\n",
        "\n",
        "    def check_phrase_coref_in_pre_post(self, pre, main, post, target_phrase):\n",
        "        \"\"\"Checks coreference chains for mentions of the target phrase across pre, main, and post.\n",
        "\n",
        "        Args:\n",
        "            pre (str): Preceding story context.\n",
        "            main (str): The main sentence where the target phrase is located.\n",
        "            post (str): Following story context.\n",
        "            target_phrase (str): The phrase to track through coreference.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary with counts and flags for where and how the phrase is mentioned,\n",
        "                  including mention counts in pre/main/post, whether referenced, and actual phrases.\n",
        "        \"\"\"\n",
        "        target_phrase = target_phrase.strip()\n",
        "        if not target_phrase:\n",
        "            return {\n",
        "                'mention_count_pre': 0,\n",
        "                'mention_count_main': 0,\n",
        "                'mention_count_post': 0,\n",
        "                'coref_chain_length': 0,\n",
        "                'target_phrase_mention_count': 0,\n",
        "                'phrase_in_chain_pre': False,\n",
        "                'phrase_in_chain_post': False,\n",
        "                'referenced_elsewhere': False,\n",
        "                'coref_mentions_pre': [],\n",
        "                'coref_mentions_post': []\n",
        "            }\n",
        "\n",
        "        combined_text = pre.strip() + \" \" + main.strip() + \" \" + post.strip()\n",
        "        pre_length = len(pre.strip())\n",
        "        main_start = pre_length + 1\n",
        "        main_length = len(main.strip())\n",
        "\n",
        "        doc = self.nlp(combined_text)\n",
        "        if not hasattr(doc, \"coref\") or not doc.coref:\n",
        "            return {\n",
        "                'mention_count_pre': 0,\n",
        "                'mention_count_main': 0,\n",
        "                'mention_count_post': 0,\n",
        "                'coref_chain_length': 0,\n",
        "                'target_phrase_mention_count': 0,\n",
        "                'phrase_in_chain_pre': False,\n",
        "                'phrase_in_chain_post': False,\n",
        "                'referenced_elsewhere': False,\n",
        "                'coref_mentions_pre': [],\n",
        "                'coref_mentions_post': []\n",
        "            }\n",
        "\n",
        "        target_chain_ids = set()\n",
        "        target_phrase_mention_count = 0\n",
        "\n",
        "        for chain_id, chain in enumerate(doc.coref):\n",
        "\n",
        "            for mention in chain.mentions:\n",
        "\n",
        "                sent_index = mention.sentence\n",
        "                start_word_idx = mention.start_word\n",
        "                end_word_idx = mention.end_word\n",
        "                words = doc.sentences[sent_index].words[start_word_idx:end_word_idx]\n",
        "                if not words:\n",
        "                    continue\n",
        "                mention_text = \" \".join([w.text for w in words]).strip()\n",
        "\n",
        "                if mention_text.lower() == target_phrase.lower():\n",
        "\n",
        "                    target_chain_ids.add(chain_id)\n",
        "                    target_phrase_mention_count += 1\n",
        "\n",
        "\n",
        "        if not target_chain_ids:\n",
        "            return {\n",
        "                'mention_count_pre': 0,\n",
        "                'mention_count_main': 0,\n",
        "                'mention_count_post': 0,\n",
        "                'coref_chain_length': 0,\n",
        "                'target_phrase_mention_count': 0,\n",
        "                'phrase_in_chain_pre': False,\n",
        "                'phrase_in_chain_post': False,\n",
        "                'referenced_elsewhere': False,\n",
        "                'coref_mentions_pre': [],\n",
        "                'coref_mentions_post': []\n",
        "            }\n",
        "\n",
        "        count_pre = count_main = count_post = 0\n",
        "        coref_mentions_pre = set()\n",
        "        coref_mentions_post = set()\n",
        "\n",
        "        for chain_id in target_chain_ids:\n",
        "            for mention in doc.coref[chain_id].mentions:\n",
        "                sent_index = mention.sentence\n",
        "                start_word_idx = mention.start_word\n",
        "                end_word_idx = mention.end_word\n",
        "                words = doc.sentences[sent_index].words[start_word_idx:end_word_idx]\n",
        "                if not words:\n",
        "                    continue\n",
        "                mention_text = \" \".join([w.text for w in words]).strip()\n",
        "                mention_start_char = words[0].start_char\n",
        "\n",
        "                region = self.get_region(\n",
        "                    offset=mention_start_char,\n",
        "                    pre_length=pre_length,\n",
        "                    main_start=main_start,\n",
        "                    main_length=main_length\n",
        "                )\n",
        "\n",
        "                if region == 'pre':\n",
        "                    count_pre += 1\n",
        "                    coref_mentions_pre.add(mention_text)\n",
        "                elif region == 'main':\n",
        "                    count_main += 1\n",
        "                elif region == 'post':\n",
        "                    count_post += 1\n",
        "                    coref_mentions_post.add(mention_text)\n",
        "\n",
        "        total_mentions = count_pre + count_main + count_post\n",
        "\n",
        "        return {\n",
        "            'mention_count_pre': count_pre,\n",
        "            'mention_count_main': count_main,\n",
        "            'mention_count_post': count_post,\n",
        "            'coref_chain_length': total_mentions,\n",
        "            'target_phrase_mention_count': target_phrase_mention_count,\n",
        "            'phrase_in_chain_pre': count_pre > 0,\n",
        "            'phrase_in_chain_post': count_post > 0,\n",
        "            'referenced_elsewhere': (count_pre > 0 or count_post > 0),\n",
        "            'coref_mentions_pre': list(coref_mentions_pre),\n",
        "            'coref_mentions_post': list(coref_mentions_post)\n",
        "        }\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Runs coreference resolution on each row and aggregates results with bin-wise averages.\n",
        "\n",
        "        For each input row:\n",
        "        - Extracts the relevant text regions and target phrase.\n",
        "        - Runs coreference resolution and determines where references occur.\n",
        "        - Calculates mention counts in pre/main/post, total mentions, and direct matches.\n",
        "\n",
        "        Then:\n",
        "        - Bins the rows (Bin 1 = first 10, others = every 10 rows)\n",
        "        - Appends a summary row to each bin with averages of numeric columns\n",
        "        - Inserts an empty row after each bin for readability\n",
        "\n",
        "        Output:\n",
        "            CSV file: 'coref_chain_counts_with_flags.csv'\n",
        "        \"\"\"\n",
        "        tqdm.pandas()\n",
        "\n",
        "        results_df = self.df.progress_apply(\n",
        "            lambda row: pd.Series(self.check_phrase_coref_in_pre_post(\n",
        "                row['Pre_Story'],\n",
        "                row['Sentence'],\n",
        "                row['Post_Story'],\n",
        "                row['target_phrase']\n",
        "            )), axis=1\n",
        "        )\n",
        "\n",
        "        # Merge results\n",
        "        self.df = pd.concat([self.df, results_df], axis=1)\n",
        "\n",
        "        # Assign Bin numbers\n",
        "        bin_labels = []\n",
        "        for i in range(len(self.df)):\n",
        "            if i < 10:\n",
        "                bin_labels.append(\"Bin 1\")\n",
        "            else:\n",
        "                bin_num = ((i - 10) // 10) + 2\n",
        "                bin_labels.append(f\"Bin {bin_num}\")\n",
        "        self.df[\"Bin\"] = bin_labels\n",
        "\n",
        "        # Insert original rows, then average rows, then blank rows\n",
        "        final_rows = []\n",
        "        for bin_name, group in self.df.groupby(\"Bin\"):\n",
        "            for _, row in group.iterrows():\n",
        "                final_rows.append(row)\n",
        "\n",
        "            # Calculate averages for numeric columns\n",
        "            avg_row = pd.Series({\n",
        "                \"mention_count_pre\": group[\"mention_count_pre\"].mean(),\n",
        "                \"mention_count_main\": group[\"mention_count_main\"].mean(),\n",
        "                \"mention_count_post\": group[\"mention_count_post\"].mean(),\n",
        "                \"coref_chain_length\": group[\"coref_chain_length\"].mean(),\n",
        "                \"target_phrase_mention_count\": group[\"target_phrase_mention_count\"].mean(),\n",
        "                \"Bin\": bin_name,\n",
        "                \"Sentence\": \"[Average]\"  # Optional marker\n",
        "            })\n",
        "            final_rows.append(avg_row)\n",
        "\n",
        "            # Empty row for spacing\n",
        "            final_rows.append(pd.Series(dtype=object))\n",
        "\n",
        "        # Final DataFrame\n",
        "        final_df = pd.DataFrame(final_rows)\n",
        "\n",
        "        # Save to CSV\n",
        "        final_df.to_csv(\"coref_chain_counts_with_flags.csv\", index=False)\n",
        "        print(\"✅ Coreference results saved to 'coref_chain_counts_with_flags.csv'\")\n",
        "\n",
        "# Entry Point\n",
        "def main():\n",
        "    \"\"\"Main entry point for running one of the available text analysis modules.\n",
        "\n",
        "    Prompts the user to:\n",
        "    - Select an analysis type (Entailment, Coherence, Average Coherence, Coreference)\n",
        "    - Provide the path to an input CSV or Excel file\n",
        "\n",
        "    Based on the user's selection, the corresponding analyzer is initialized and executed.\n",
        "\n",
        "    Options:\n",
        "        1. Entailment Score\n",
        "        2. Coherence Score\n",
        "        3. Average Coherence Between Sentences\n",
        "        4. Coreference Resolution\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the user's choice is not among the allowed options (1–4).\n",
        "    \"\"\"\n",
        "    print(\"Select an analysis to run:\")\n",
        "    print(\"1. Entailment Score\")\n",
        "    print(\"2. Coherence Score\")\n",
        "    print(\"3. Average Coherence Between Sentences\")\n",
        "    print(\"4. Coreference Resolution\")\n",
        "\n",
        "    choice = input(\"Enter choice (1-4): \")\n",
        "    filepath = input(\"Enter path to CSV file: \")\n",
        "\n",
        "    analyzers = {\n",
        "        '1': EntailmentAnalyzer,\n",
        "        '2': CoherenceAnalyzer,\n",
        "        '3': AverageCoherenceAnalyzer,\n",
        "        '4': CoreferenceAnalyzer\n",
        "    }\n",
        "\n",
        "    analyzer_class = analyzers.get(choice)\n",
        "    if analyzer_class:\n",
        "        analyzer = analyzer_class(filepath)\n",
        "        analyzer.run()\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter 1-4.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "QOEk7R48x9OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the csv file"
      ],
      "metadata": {
        "id": "KVxChJ587lT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # Fix spaces around apostrophes: it 's → it's\n",
        "    text = re.sub(r\"\\s+'\\s*\", \"'\", text)\n",
        "\n",
        "    # Fix comma spacing: \"word ,word\" → \"word, word\"\n",
        "    text = re.sub(r\"\\s*,\\s*\", \", \", text)\n",
        "    text = re.sub(r\",\\s+\", \", \", text)  # normalize extra spaces after comma\n",
        "\n",
        "    # Fix quote spacing: remove space inside quotes → \" hello \" → \"hello\"\n",
        "    text = re.sub(r'\"\\s*(.*?)\\s*\"', r'\"\\1\"', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Strip leading/trailing spaces\n",
        "    return text.strip()\n",
        "\n",
        "def clean_csv_text(input_path, output_path):\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    # Apply cleaning to all cells\n",
        "    df_cleaned = df.applymap(clean_text)\n",
        "\n",
        "    # Save cleaned output\n",
        "    df_cleaned.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Cleaned CSV saved to: {output_path}\")\n",
        "\n",
        "# Example usage:\n",
        "clean_csv_text(\"/content/final_50_sample_dataset.csv\", \"/content/cleaned_final_50_sample_dataset.csv\")\n"
      ],
      "metadata": {
        "id": "V9ZA2Tsw7Tig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}